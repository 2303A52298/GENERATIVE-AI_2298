{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "(1 ponto) Write Python code from scratch to find error metrics of deep learning model. Actual\n",
        "values and deep learning model predicted values are shown in Table 1. Also compare the results\n",
        "with the outcomes of libraries\n",
        "YActual YP red\n",
        "20 20.5\n",
        "30 30.3\n",
        "40 40.2\n",
        "50 50.6\n",
        "60 60.7\n",
        "Tabela 1: YActual Vs. YP red"
      ],
      "metadata": {
        "id": "mePc2DGbMnbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "YActual = np.array([20, 30, 40, 50, 60])\n",
        "YPred = np.array([20.5, 30.3, 40.2, 50.6, 60.7])\n",
        "MAE = np.mean(np.abs(YActual - YPred))\n",
        "MSE = np.mean((YActual - YPred) ** 2)\n",
        "RMSE = np.sqrt(MSE)\n",
        "SS_total = np.sum((YActual - np.mean(YActual)) ** 2)\n",
        "SS_residual = np.sum((YActual - YPred) ** 2)\n",
        "R2 = 1 - (SS_residual / SS_total)\n",
        "print(f\"Manual Error Metrics:\")\n",
        "print(f\"Mean Absolute Error (MAE): {MAE}\")\n",
        "print(f\"Mean Squared Error (MSE): {MSE}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {RMSE}\")\n",
        "print(f\"R-squared (R²): {R2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Rb3m8gq2M8tA",
        "outputId": "18ffb2cf-c60c-4eb1-be11-f3cb866c0422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Error Metrics:\n",
            "Mean Absolute Error (MAE): 0.4600000000000016\n",
            "Mean Squared Error (MSE): 0.24600000000000147\n",
            "Root Mean Squared Error (RMSE): 0.49598387070549127\n",
            "R-squared (R²): 0.99877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAE_sklearn = mean_absolute_error(YActual, YPred)\n",
        "MSE_sklearn = mean_squared_error(YActual, YPred)\n",
        "RMSE_sklearn = np.sqrt(MSE_sklearn)\n",
        "R2_sklearn = r2_score(YActual, YPred)\n",
        "print(\"\\nSklearn Error Metrics:\")\n",
        "print(f\"Mean Absolute Error (MAE) using sklearn: {MAE_sklearn}\")\n",
        "print(f\"Mean Squared Error (MSE) using sklearn: {MSE_sklearn}\")\n",
        "print(f\"Root Mean Squared Error (RMSE) using sklearn: {RMSE_sklearn}\")\n",
        "print(f\"R-squared (R²) using sklearn: {R2_sklearn}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fetOPYnvOuV4",
        "outputId": "da455714-c6c1-4e0f-c361-21898d06d9b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sklearn Error Metrics:\n",
            "Mean Absolute Error (MAE) using sklearn: 0.4600000000000016\n",
            "Mean Squared Error (MSE) using sklearn: 0.24600000000000147\n",
            "Root Mean Squared Error (RMSE) using sklearn: 0.49598387070549127\n",
            "R-squared (R²) using sklearn: 0.99877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2 :(1 ponto) Write python code from scratch to find evaluation metrics of deep learning model.\n",
        "Actual values and deep learning model predicted values are shown in Table 2. Also compare the\n",
        "results with outcome of libraries\n",
        "YActual YP red\n",
        "0 0 1 1 2 0\n",
        "0 0 1 0 2 0\n",
        "0 1 1 2 2 1\n",
        "0 2 1 0 2 2\n",
        "0 2 1 2 2 2\n",
        "Tabela 2: YActual Vs. YP red\n",
        "• Expected Leaning Outcomes from this assignment related to python\n",
        "– Students are able to understand deep learning model metrics\n",
        "– Students are able to write code in python to find deep learning model metrics\n",
        "– Students are able to use python libraries to find deep learning model metrics\n",
        "• Naming cinvention"
      ],
      "metadata": {
        "id": "rKhNE2WpO42G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "YActual = np.array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2])\n",
        "YPred = np.array([0, 1, 0, 0, 0, 0, 1, 2, 1, 2, 2, 2])\n",
        "accuracy = np.sum(YActual == YPred) / len(YActual)\n",
        "precision = {}\n",
        "recall = {}\n",
        "f1 = {}\n",
        "classes = np.unique(YActual)\n",
        "\n",
        "for cls in classes:\n",
        "    tp = np.sum((YActual == cls) & (YPred == cls))\n",
        "    fp = np.sum((YActual != cls) & (YPred == cls))\n",
        "    fn = np.sum((YActual == cls) & (YPred != cls))\n",
        "    tn = np.sum((YActual != cls) & (YPred != cls))\n",
        "\n",
        "    precision[cls] = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "    recall[cls] = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "    f1[cls] = 2 * (precision[cls] * recall[cls]) / (precision[cls] + recall[cls]) if (precision[cls] + recall[cls]) != 0 else 0\n",
        "conf_matrix = confusion_matrix(YActual, YPred)\n",
        "print(f\"Manual Error Metrics:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "for cls in classes:\n",
        "    print(f\"Class {cls}: Precision = {precision[cls]}, Recall = {recall[cls]}, F1-Score = {f1[cls]}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C74BD7JAPEUG",
        "outputId": "74f51964-83ec-4cac-fdef-ed63b640324d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Error Metrics:\n",
            "Accuracy: 0.3333333333333333\n",
            "Class 0: Precision = 0.4, Recall = 0.5, F1-Score = 0.4444444444444445\n",
            "Class 1: Precision = 0.3333333333333333, Recall = 0.25, F1-Score = 0.28571428571428575\n",
            "Class 2: Precision = 0.25, Recall = 0.25, F1-Score = 0.25\n",
            "Confusion Matrix:\n",
            "[[2 1 1]\n",
            " [1 1 2]\n",
            " [2 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_sklearn = accuracy_score(YActual, YPred)\n",
        "precision_sklearn = precision_score(YActual, YPred, average=None, labels=np.unique(YActual))\n",
        "recall_sklearn = recall_score(YActual, YPred, average=None, labels=np.unique(YActual))\n",
        "f1_sklearn = f1_score(YActual, YPred, average=None, labels=np.unique(YActual))\n",
        "conf_matrix_sklearn = confusion_matrix(YActual, YPred)\n",
        "print(\"\\nSklearn Error Metrics:\")\n",
        "print(f\"Accuracy using sklearn: {accuracy_sklearn}\")\n",
        "print(f\"Precision using sklearn: {precision_sklearn}\")\n",
        "print(f\"Recall using sklearn: {recall_sklearn}\")\n",
        "print(f\"F1-Score using sklearn: {f1_sklearn}\")\n",
        "print(f\"Confusion Matrix using sklearn:\\n{conf_matrix_sklearn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAEfdkdmPeuH",
        "outputId": "ebbd3c52-8bfa-4427-835c-1103a448db71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sklearn Error Metrics:\n",
            "Accuracy using sklearn: 0.3333333333333333\n",
            "Precision using sklearn: [0.4        0.33333333 0.25      ]\n",
            "Recall using sklearn: [0.5  0.25 0.25]\n",
            "F1-Score using sklearn: [0.44444444 0.28571429 0.25      ]\n",
            "Confusion Matrix using sklearn:\n",
            "[[2 1 1]\n",
            " [1 1 2]\n",
            " [2 1 1]]\n"
          ]
        }
      ]
    }
  ]
}